{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThatCodeCodingGuy/Toxic-Comment-Detector/blob/main/modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyDexFdLQuMs"
      },
      "source": [
        "# **Importing Necessary Packages and Modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bRqnfr9BA23v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics, svm\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8-6HNyHRqGs",
        "outputId": "01a17043-511f-4063-d736-3a68bd9ba5d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Gauri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUOEYrAqYk1s"
      },
      "source": [
        "# **Glancing at the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zvSL51KTIe-h"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('toxicity.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8Q-fRUDQI2Hy",
        "outputId": "8502ed43-644b-4403-fe7d-c17bd916694a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elon Musk is a piece of shit, greedy capitalis...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The senile credit card shrill from Delaware ne...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>He does that a lot -- makes everyone look good...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F*ck Lizzo</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Epstein and trump were best buds!!! Pedophiles...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text is_toxic\n",
              "0  Elon Musk is a piece of shit, greedy capitalis...    Toxic\n",
              "1  The senile credit card shrill from Delaware ne...    Toxic\n",
              "2  He does that a lot -- makes everyone look good...    Toxic\n",
              "3                                         F*ck Lizzo    Toxic\n",
              "4  Epstein and trump were best buds!!! Pedophiles...    Toxic"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "NAITpDVSKUJZ",
        "outputId": "a19268b5-16ee-40b2-aea1-75679a609f9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_toxic</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>\" Amazing Humans\"????Not in my book( Pun intended) this is terrible,you do NOT confuse infants that \"Drag Queens\" are the norm, absolutely sickening that these people are allowed to do this kind of propaganda to infants and children!!</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\"Guns don't kill people....Alec Baldwin does.\"</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\"How to correctly hit a #woman\" #feminism #islam #terrorist</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\"I am asking you in a very educated manner\" bitch get out of the fucking car</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>\"I'm a full on rapist... I mean a philanthropist\" \\n \\n -Bill Gates</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{nods in agreement} Stay in school and keep practicing, kids</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‚ÄúBitch, you ain‚Äôt takin SHIT, but‚Äôchoo can DAMN sure take it up with me right here and now‚Äù. \\n But see, I don‚Äôt have anxiety, and my dog weighs 122 pounds, so . . . . . .</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‚ÄúYou Trumpsters better pray that liberals never gain control of the WH again because we are going to pay you back so fucking hard for all of this shit. Planned Parenthoods on every damn corner. We're going to repaint Air Force One, pussy hat pink and fly it over your beloved Bible Belt 6 days a week, tossing birth control pills, condoms &amp; atheist literature from the cockpit. We're going to tax your mega churches so bad Joel Olsteen will need to get a job at Chik Fil A to pay his light bill. Speaking of Chik Fil A, we're buying all those and giving them to any LGBTQ person your sick cult leaders tortured with conversion therapy. Have fun with the new menu you bigoted fucks. Try the McPence. It's a boiled unseasoned chicken breast that you have to eat in the closet with your mother. We‚Äôre going to gather up ALL of your guns, melt them down and turn them into a gargantuan metal mountain emblazoned with the face of Hillary Clinton. ALL parks will be renamed Rosa Parks asap. We're replacing Confederate statues with BLM Leaders &amp; Mexican immigrants. Every single public school will be renamed after a child that was kidnapped by this regime. And after we fumigate the WH, we're repainting the whole thing rainbow. Fox News will be taken over and turned into a family refugee shelter. We're turning Hannity's office into a giant unisex bathroom with changing tables &amp; free tampons. And every single time a Trumpster complains about any of the changes, we're adding an openly gay character to a Disney movie.\"</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‚ò≠ WHY DO #LIBERALS HATE #AMERICA? ‚òπ WHY DOES A #LIBERAL WORSHIP #COMMUNISM? ‚ò≠ #LIBERALISM is a Severe Disease and Mental Illness ‚Äì Find a Cure - #Democrats #LiberalLogic #Leftists #LibTard #LiberalHypocrisy #JoeBiden - q-7391</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>üîªüëΩüëÅüîª\\n ANTI ASIAN and LOVING it!!!</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    is_toxic\n",
              "text                                                        \n",
              "\" Amazing Humans\"????Not in my book( Pun intend...         1\n",
              "\"Guns don't kill people....Alec Baldwin does.\"             1\n",
              "\"How to correctly hit a #woman\" #feminism #isla...         1\n",
              "\"I am asking you in a very educated manner\" bit...         1\n",
              "\"I'm a full on rapist... I mean a philanthropis...         1\n",
              "...                                                      ...\n",
              "{nods in agreement} Stay in school and keep pra...         1\n",
              "‚ÄúBitch, you ain‚Äôt takin SHIT, but‚Äôchoo can DAMN...         1\n",
              "‚ÄúYou Trumpsters better pray that liberals never...         1\n",
              "‚ò≠ WHY DO #LIBERALS HATE #AMERICA? ‚òπ WHY DOES A ...         1\n",
              "üîªüëΩüëÅüîª\\n ANTI ASIAN and LOVING it!!!                         1\n",
              "\n",
              "[999 rows x 1 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby('text').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "lKSefo6wOvb9",
        "outputId": "6b7ec834-8281-437b-ce21-06a7a1080845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEbCAYAAAAh9sTfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPvElEQVR4nO3df6zddX3H8efLFhRRKT86xtpq2UQNyxSwYxjNdJAtgjqIUaZTaEhjzYaZRpPJ9seWxSWTLBOn2RwdOItxKv4anSNurGCc2UQviviDMTsGox3YioAyf4Lv/XE/1x3Lbe9t7zn3Sz/n+UhOzufXOed9kuZ1v/2c7/ecVBWSpL48ZugCJEnjZ7hLUocMd0nqkOEuSR0y3CWpQ4a7JHVo5dAFABx33HG1fv36ocuQpEPKTTfd9I2qWj3f3KMi3NevX8/MzMzQZUjSISXJnfuac1tGkjpkuEtShwx3SeqQ4S5JHTLcJalDiwr3JHck+VKSm5PMtLFjklyX5Gvt/ug2niTvSLIjyS1JTpvkG5AkPdKBHLn/SlWdUlUbWv8SYHtVnQRsb32As4GT2m0z8K5xFStJWpylbMucC2xt7a3AeSPjV9WszwCrkpywhNeRJB2gxV7EVMA/JSng8qraAhxfVXe3+XuA41t7DXDXyGN3trG7R8ZIspnZI3ue/OQnH1z1y2z9Jf8wdAldueOtLxq6BKlbiw3351XVriQ/BVyX5N9HJ6uqWvAvWvsDsQVgw4YN/hyUtAQeeIxXDwcei9qWqapd7X438DHgdODrc9st7X53W74LWDfy8LVtTJK0TBYM9yRHJnniXBv4NeDLwDZgY1u2EbimtbcBF7azZs4AHhjZvpEkLYPFbMscD3wsydz6v62qTyT5HHB1kk3AncD5bf21wDnADuA7wEVjr1qStF8LhntV3Q48a57xe4Gz5hkv4OKxVCdJOiheoSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0KLDPcmKJF9I8vHWPzHJjUl2JPlgksPb+GNbf0ebXz+h2iVJ+3AgR+6vB24d6V8KXFZVTwXuAza18U3AfW38srZOkrSMFhXuSdYCLwKuaP0AZwIfbku2Aue19rmtT5s/q62XJC2TxR65vx34XeBHrX8scH9VPdT6O4E1rb0GuAugzT/Q1kuSlsmC4Z7kxcDuqrppnC+cZHOSmSQze/bsGedTS9LUW8yR+3OBX09yB/ABZrdj/hxYlWRlW7MW2NXau4B1AG3+KODevZ+0qrZU1Yaq2rB69eolvQlJ0k9aMNyr6veqam1VrQdeAVxfVa8CbgBe1pZtBK5p7W2tT5u/vqpqrFVLkvZrKee5vxl4Y5IdzO6pX9nGrwSObeNvBC5ZWomSpAO1cuEl/6+qPgl8srVvB06fZ833gJePoTZJ0kHyClVJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SerQguGe5HFJPpvki0m+kuSP2viJSW5MsiPJB5Mc3sYf2/o72vz6Cb8HSdJeFnPk/n3gzKp6FnAK8MIkZwCXApdV1VOB+4BNbf0m4L42fllbJ0laRguGe816sHUPa7cCzgQ+3Ma3Aue19rmtT5s/K0nGVbAkaWGL2nNPsiLJzcBu4DrgP4H7q+qhtmQnsKa11wB3AbT5B4Bj53nOzUlmkszs2bNnSW9CkvSTFhXuVfVwVZ0CrAVOB56x1Beuqi1VtaGqNqxevXqpTydJGnFAZ8tU1f3ADcBzgFVJVraptcCu1t4FrANo80cB946jWEnS4izmbJnVSVa19hHArwK3MhvyL2vLNgLXtPa21qfNX19VNcaaJUkLWLnwEk4AtiZZwewfg6ur6uNJvgp8IMkfA18ArmzrrwTem2QH8E3gFROoW5K0HwuGe1XdApw6z/jtzO6/7z3+PeDlY6lOknRQvEJVkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KEFwz3JuiQ3JPlqkq8keX0bPybJdUm+1u6PbuNJ8o4kO5LckuS0Sb8JSdJPWsyR+0PAm6rqZOAM4OIkJwOXANur6iRge+sDnA2c1G6bgXeNvWpJ0n4tGO5VdXdVfb61vw3cCqwBzgW2tmVbgfNa+1zgqpr1GWBVkhPGXbgkad8OaM89yXrgVOBG4PiqurtN3QMc39prgLtGHrazje39XJuTzCSZ2bNnz4HWLUnaj0WHe5InAB8B3lBV3xqdq6oC6kBeuKq2VNWGqtqwevXqA3moJGkBiwr3JIcxG+zvq6qPtuGvz223tPvdbXwXsG7k4WvbmCRpmSzmbJkAVwK3VtXbRqa2ARtbeyNwzcj4he2smTOAB0a2byRJy2DlItY8F7gA+FKSm9vY7wNvBa5Osgm4Ezi/zV0LnAPsAL4DXDTOgiVJC1sw3Kvq00D2MX3WPOsLuHiJdUmSlsArVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdWjDck7w7ye4kXx4ZOybJdUm+1u6PbuNJ8o4kO5LckuS0SRYvSZrfYo7c3wO8cK+xS4DtVXUSsL31Ac4GTmq3zcC7xlOmJOlALBjuVfUp4Jt7DZ8LbG3trcB5I+NX1azPAKuSnDCmWiVJi3Swe+7HV9XdrX0PcHxrrwHuGlm3s41JkpbRkj9QraoC6kAfl2RzkpkkM3v27FlqGZKkEQcb7l+f225p97vb+C5g3ci6tW3sEapqS1VtqKoNq1evPsgyJEnzOdhw3wZsbO2NwDUj4xe2s2bOAB4Y2b6RJC2TlQstSPJ+4AXAcUl2An8IvBW4Oskm4E7g/Lb8WuAcYAfwHeCiCdQsSVrAguFeVa/cx9RZ86wt4OKlFiVJWhqvUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA5NJNyTvDDJbUl2JLlkEq8hSdq3sYd7khXAXwBnAycDr0xy8rhfR5K0b5M4cj8d2FFVt1fVD4APAOdO4HUkSfuwcgLPuQa4a6S/E/ilvRcl2Qxsbt0Hk9w2gVqm1XHAN4YuYiG5dOgKNAD/bY7XU/Y1MYlwX5Sq2gJsGer1e5Zkpqo2DF2HtDf/bS6fSWzL7ALWjfTXtjFJ0jKZRLh/DjgpyYlJDgdeAWybwOtIkvZh7NsyVfVQktcB/wisAN5dVV8Z9+tov9zu0qOV/zaXSapq6BokSWPmFaqS1CHDXZI6ZLhLmpgkRyZ5zEj/MUkeP2RN08Jw70CSi5OsGukfneS3ByxJmrMdGA3zxwP/PFAtU8Vw78Nrqur+uU5V3Qe8ZrhypB97XFU9ONdpbY/cl4Hh3ocVSTLXaV/edviA9Uhz/jfJaXOdJM8GvjtgPVNjsK8f0Fh9Avhgkstb/7VtTBraG4APJfkfIMBPA78xaEVTwvPcO9A+sHotcFYbug64oqoeHq4qaVaSw4Cnt+5tVfXDIeuZFoa7pLFLcmZVXZ/kpfPNV9VHl7umaeO2zCEsydVVdX6SLwGP+CtdVc8coCwJ4PnA9cBL5pkrwHCfMI/cD2FJTqiqu5PM+53OVXXnctck6dHBs2UOYVV1d2seWVV3jt6AE4esTQJI8t4kR430n5Jk+5A1TQvDvQ9XJ3lzZh2R5J3AnwxdlAR8GrgxyTlJXsPsh/1vH7ak6eC2TAeSHAlcCjwbeCLwPuDSqvrRoIVJQJLnATcw+/N6p1bVPQOXNBU8cu/DD5m9MOQI4HHAfxnsejRIcgHwbuBC4D3AtUmeNWhRU8Ij9w4k+SJwDfAWZn+A+K+AH1TVywctTFMvyd8Bm6tqd+ufDlxeVacOWtgUMNw7kGRDVc3sNXZBVb13qJqkOe3nNp/Wurcxmzs/GLCkqWC4d6BdAfhbwC+3oU8ye3TklYAaVJLnA1cBdzD79QPrgI1V9akh65oGhnsHklwBHAZsbUMXAA9Vld8MqUEluQn4zaq6rfWfBry/qp49bGX98wrVQ1iSlVX1EPCLVTX6IdX1bR9eGtphc8EOUFX/0f6nqQnzbJlD22fb/cNJfm5uMMnPAn5pmAaT5HWtOZPkiiQvaLe/Bmb291iNh9syh7AkX6iqU5OcyexpZre3qfXARVV1w1C1abol+XxVnZbkscDrgOe2qX8B/rKqvj9cddPBcD+EJdkJvK11jwBWtPbDwHer6m3zPlCasLlwH7qOaeae+6FtBfAEZs9CGLWS2StVpaE8M8m35hkPUFX1pOUuaNp45H4I8+hIj1ZzW4ZD1zHN/ED10Lb3EbskAYb7oe6shZdIg/jQ0AVMO7dlJKlDHrlLUocMd0kTk+QRvwg235jGz3CXNEkfmWfsw8texRTyPHdJY5fkGcDPA0cleenI1JOY/UEZTZjhLmkSng68GFgFvGRk/NuA31a6DDxbRtLEJHlOVf3b0HVMI/fcJU3SXUk+lmR3u30kydqhi5oGhrukSfobYBvwM+32921ME+a2jKSJSfLFvX5IhiQ3V9UpA5U0NTxylzRJ30jy6iQr2u3VwL1DFzUNPHKXNDFJngK8E3gOUMC/Ar9TVf89aGFTwHCXpA55nruksUvyB/uZrqp6y7IVM6U8cpc0dkneNM/wkcAm4NiqesIylzR1DHdJE5XkicDrmQ32q4E/q6rdw1bVP7dlJE1EkmOANwKvArYCp1XVfcNWNT0Md0ljl+RPgZcCW4BfqKoHBy5p6rgtI2nskvwI+D7wELOnQP54itkPVJ80SGFTxHCXpA55haokdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0P8BK0nRl8pxeQoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['is_toxic'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlAOWex3RF4j"
      },
      "source": [
        "# **Cleaning the Text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mbEwaAgmO0yI"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # make text lowercase\n",
        "    text = text.lower()\n",
        "    # removing text within parentheses\n",
        "    text = re.sub('\\(.*?\\)', '', text)\n",
        "    # removing numbers\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    # if there's more than 1 whitespace, then make it just 1\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    # if there's a new line, then make it a whitespace\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    # removing any quotes\n",
        "    text = re.sub('\\\"+', '', text)\n",
        "    # getting rid of punctuations\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "clean = lambda x: clean_text(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WDGuPCrPPIp8"
      },
      "outputs": [],
      "source": [
        "df['clean_text'] = df['text'].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1dvpzhFnPUc-",
        "outputId": "f62cf385-3d84-4d3c-c1a3-943040121e5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_toxic</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elon Musk is a piece of shit, greedy capitalis...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>elon musk is a piece of shit greedy capitalist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The senile credit card shrill from Delaware ne...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>the senile credit card shrill from delaware ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>He does that a lot -- makes everyone look good...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>he does that a lot  makes everyone look good b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F*ck Lizzo</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>fck lizzo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Epstein and trump were best buds!!! Pedophiles...</td>\n",
              "      <td>Toxic</td>\n",
              "      <td>epstein and trump were best buds pedophiles wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text is_toxic  \\\n",
              "0  Elon Musk is a piece of shit, greedy capitalis...    Toxic   \n",
              "1  The senile credit card shrill from Delaware ne...    Toxic   \n",
              "2  He does that a lot -- makes everyone look good...    Toxic   \n",
              "3                                         F*ck Lizzo    Toxic   \n",
              "4  Epstein and trump were best buds!!! Pedophiles...    Toxic   \n",
              "\n",
              "                                          clean_text  \n",
              "0  elon musk is a piece of shit greedy capitalist...  \n",
              "1  the senile credit card shrill from delaware ne...  \n",
              "2  he does that a lot  makes everyone look good b...  \n",
              "3                                          fck lizzo  \n",
              "4  epstein and trump were best buds pedophiles wh...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lftASNqmQyfW"
      },
      "outputs": [],
      "source": [
        "text_df = df[['clean_text', 'is_toxic']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eo4cG4uIRzyJ",
        "outputId": "997b5900-1298-4196-9724-4fd6e69962a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>is_toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elon musk is a piece of shit greedy capitalist...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the senile credit card shrill from delaware ne...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he does that a lot  makes everyone look good b...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fck lizzo</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>epstein and trump were best buds pedophiles wh...</td>\n",
              "      <td>Toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text is_toxic\n",
              "0  elon musk is a piece of shit greedy capitalist...    Toxic\n",
              "1  the senile credit card shrill from delaware ne...    Toxic\n",
              "2  he does that a lot  makes everyone look good b...    Toxic\n",
              "3                                          fck lizzo    Toxic\n",
              "4  epstein and trump were best buds pedophiles wh...    Toxic"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tpX2gQUhR2GG"
      },
      "outputs": [],
      "source": [
        "text_df['is_toxic'] = text_df['is_toxic'].replace('Toxic', 1)\n",
        "text_df['is_toxic'] = text_df['is_toxic'].replace('Not Toxic', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KxXPs3BZSM4h",
        "outputId": "8433f9e3-8696-49de-9716-007e8ad5a87d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>is_toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elon musk is a piece of shit greedy capitalist...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the senile credit card shrill from delaware ne...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he does that a lot  makes everyone look good b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fck lizzo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>epstein and trump were best buds pedophiles wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  is_toxic\n",
              "0  elon musk is a piece of shit greedy capitalist...         1\n",
              "1  the senile credit card shrill from delaware ne...         1\n",
              "2  he does that a lot  makes everyone look good b...         1\n",
              "3                                          fck lizzo         1\n",
              "4  epstein and trump were best buds pedophiles wh...         1"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ost_BsGfSd7j"
      },
      "outputs": [],
      "source": [
        "data = text_df['clean_text']\n",
        "target = text_df['is_toxic']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM5thBTHZeG4"
      },
      "source": [
        "# Looking at the most frequent words of unclean and clean versions of the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Cc7SwoaL6A"
      },
      "source": [
        "*Unclean Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WaRA8tArSmOL"
      },
      "outputs": [],
      "source": [
        "# looking at the unclean data\n",
        "def unfiltered_tokens(text):\n",
        "    dirty_tokens = nltk.word_tokenize(text)\n",
        "    return dirty_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IAcIueqWSvNr"
      },
      "outputs": [],
      "source": [
        "# applying this function to the `clean_text` column\n",
        "unfiltered_data = list(map(unfiltered_tokens, data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vZfVJmITBsi",
        "outputId": "d4b503e0-b030-440a-ab0e-3f76ea15d03a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 916),\n",
              " ('and', 594),\n",
              " ('a', 590),\n",
              " ('to', 538),\n",
              " ('i', 477),\n",
              " ('of', 399),\n",
              " ('you', 394),\n",
              " ('is', 376),\n",
              " ('that', 299),\n",
              " ('in', 285),\n",
              " ('it', 284),\n",
              " ('for', 235),\n",
              " ('‚Äô', 230),\n",
              " ('this', 229),\n",
              " ('are', 184),\n",
              " ('he', 166),\n",
              " ('be', 158),\n",
              " ('with', 154),\n",
              " ('on', 141),\n",
              " ('your', 139)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# turning this into a readable list and getting most frequent 20 words\n",
        "flat_unfiltered = [item for sublist in unfiltered_data for item in sublist]\n",
        "dirty_corpus_freqdist = FreqDist(flat_unfiltered)\n",
        "dirty_corpus_freqdist.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfoRVb7SamsH"
      },
      "source": [
        "*Clean Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GqgVX1-uTEzV"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EmkEJu49TIPX"
      },
      "outputs": [],
      "source": [
        "def process_text(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
        "    return stopwords_removed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aoWlDzxkTSiQ"
      },
      "outputs": [],
      "source": [
        "# applying the above function to our data/features \n",
        "processed_data = list(map(process_text, data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGVhnLVvTbub",
        "outputId": "74b07ec3-d423-455b-e33e-6f4e2af8bdeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5047"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_vocab = set()\n",
        "for comment in processed_data:\n",
        "    total_vocab.update(comment)\n",
        "len(total_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMya19aqTds6",
        "outputId": "7aff28c2-3509-46d6-c97a-edf6771f960c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('‚Äô', 230),\n",
              " ('like', 123),\n",
              " ('people', 85),\n",
              " ('get', 74),\n",
              " ('good', 68),\n",
              " ('would', 63),\n",
              " ('go', 61),\n",
              " ('im', 52),\n",
              " ('see', 51),\n",
              " ('love', 50),\n",
              " ('never', 48),\n",
              " ('one', 47),\n",
              " ('know', 46),\n",
              " ('dont', 46),\n",
              " ('biden', 45),\n",
              " ('really', 44),\n",
              " ('time', 42),\n",
              " ('think', 42),\n",
              " ('way', 40),\n",
              " ('joe', 39)]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# turning the data into a readable list and getting top 20 words\n",
        "flat_filtered = [item for sublist in processed_data for item in sublist]\n",
        "clean_corpus_freqdist = FreqDist(flat_filtered)\n",
        "clean_corpus_freqdist.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14DV6ruxS0Dg"
      },
      "source": [
        "# **Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uG5FLmB0TiWE"
      },
      "outputs": [],
      "source": [
        "# creating a list with all lemmatized outputs\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "lemmatized_output = []\n",
        "\n",
        "for listy in processed_data:\n",
        "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in listy])\n",
        "    lemmatized_output.append(lemmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ky6B4dIhTvnw"
      },
      "outputs": [],
      "source": [
        "X_lem = lemmatized_output\n",
        "y_lem = target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KleJj3fwVm_H"
      },
      "source": [
        "# **Splitting the dataset into Train-Test and Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "C9kpnRzgUnzw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_lem, y_lem, test_size=0.20, random_state=15)\n",
        "\n",
        "# using tf_idf vectorizor with bigrams\n",
        "tfidf = TfidfVectorizer(stop_words= stop_words, ngram_range=(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1cY8p9QAUsg_"
      },
      "outputs": [],
      "source": [
        "tfidf_data_train = tfidf.fit_transform(X_train)\n",
        "tfidf_data_test = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N9HOm8-V02Z"
      },
      "source": [
        "# **Modeling: SVM, Logistic Regression and Multinomial Naive Bayes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQd18Nu6Wydp"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LIn4Zoj5Uvja"
      },
      "outputs": [],
      "source": [
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', class_weight='balanced', random_state=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzYrCVDOUyhW",
        "outputId": "1f12a4cb-a3ca-4128-e6b1-2608413e38c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%%time` not found.\n"
          ]
        }
      ],
      "source": [
        "# fitting the dataset to the model and predicting the labels on validation dataset\n",
        "%%time \n",
        "SVM.fit(tfidf_data_train, y_train)\n",
        "SVM_test_preds = SVM.predict(tfidf_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Co-vU-CEU1Xm"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'SVM_test_preds' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-33-6d6be48e607f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# measuring the performance fo the model by several metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSVM_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVM_test_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSVM_recall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVM_test_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mSVM_f1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVM_test_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mSVM_weighted_f1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVM_test_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'SVM_test_preds' is not defined"
          ]
        }
      ],
      "source": [
        "# measuring the performance fo the model by several metrics\n",
        "SVM_precision = precision_score(y_test, SVM_test_preds)\n",
        "SVM_recall = recall_score(y_test, SVM_test_preds)\n",
        "SVM_f1_score = f1_score(y_test, SVM_test_preds)\n",
        "SVM_weighted_f1_score = f1_score(y_test, SVM_test_preds, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpN3fibzU5T9",
        "outputId": "6767d817-91a0-4c38-e31b-01cdd8a0f644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8218\n",
            "Recall: 0.83\n",
            "F1 Score: 0.8259\n",
            "Weighted F1 Score: 0.825\n"
          ]
        }
      ],
      "source": [
        "# printing evaluation metrics up to 4th decimal place\n",
        "print('Precision: {:.4}'.format(SVM_precision))\n",
        "print('Recall: {:.4}'.format(SVM_recall))\n",
        "print('F1 Score: {:.4}'.format(SVM_f1_score))\n",
        "print('Weighted F1 Score: {:.4}'.format(SVM_weighted_f1_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ykmnqx_U8Ez"
      },
      "outputs": [],
      "source": [
        "# creating dictionary with all metrics\n",
        "metric_dict = {}\n",
        "metric_dict['SVM'] = {'precision': SVM_precision, 'recall': SVM_recall, 'f1_score': SVM_f1_score}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47mx2OalW1zi"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUhcOu2WVPdE"
      },
      "outputs": [],
      "source": [
        "logreg_baseline = LogisticRegression(penalty='l2', class_weight='balanced', random_state=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgyde0YRVaWV",
        "outputId": "b76ea648-517e-48ab-b2ef-7b59d65dead2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 77.6 ms, sys: 109 ms, total: 187 ms\n",
            "Wall time: 112 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "logreg_baseline.fit(tfidf_data_train, y_train)\n",
        "logreg_test_preds = logreg_baseline.predict(tfidf_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fH1QqKSVnA5"
      },
      "outputs": [],
      "source": [
        "logreg_precision = precision_score(y_test, logreg_test_preds)\n",
        "logreg_recall = recall_score(y_test, logreg_test_preds)\n",
        "logreg_f1_score = f1_score(y_test, logreg_test_preds)\n",
        "logreg_weighted_f1_score = f1_score(y_test, logreg_test_preds, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzdPt5VWVv_T",
        "outputId": "e2fda0fa-fc77-4b56-a081-32f9142e43b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8163\n",
            "Recall: 0.8\n",
            "F1 Score: 0.8081\n"
          ]
        }
      ],
      "source": [
        "print('Precision: {:.4}'.format(logreg_precision))\n",
        "print('Recall: {:.4}'.format(logreg_recall))\n",
        "print('F1 Score: {:.4}'.format(logreg_f1_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNF3gVxAXGny"
      },
      "outputs": [],
      "source": [
        "metric_dict['Logistic Regression'] = {'precision': logreg_precision, 'recall': logreg_recall, 'f1_score': logreg_f1_score}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_m4wtEMXFBw"
      },
      "source": [
        "# **Multinomial Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dptE19hW2-l"
      },
      "outputs": [],
      "source": [
        "bayes = MultinomialNB(alpha = .01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIwSq9qvW6x0"
      },
      "outputs": [],
      "source": [
        "bayes.fit(tfidf_data_train, y_train)\n",
        "bayes_test_preds = bayes.predict(tfidf_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7twxHFQW9QU"
      },
      "outputs": [],
      "source": [
        "bayes_precision = precision_score(y_test, bayes_test_preds)\n",
        "bayes_recall = recall_score(y_test, bayes_test_preds)\n",
        "bayes_f1_score = f1_score(y_test, bayes_test_preds)\n",
        "bayes_f1_weighted = f1_score(y_test, bayes_test_preds, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0zj5CzWW_52",
        "outputId": "bb593255-6439-44bb-ab0a-c3c35d72ca2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8148\n",
            "Recall: 0.88\n",
            "F1 Score: 0.8462\n"
          ]
        }
      ],
      "source": [
        "print('Precision: {:.4}'.format(bayes_precision))\n",
        "print('Recall: {:.4}'.format(bayes_recall))\n",
        "print('F1 Score: {:.4}'.format(bayes_f1_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i_yLMmxXCIN"
      },
      "outputs": [],
      "source": [
        "metric_dict[ 'Naive Bayes'] = {'precision': bayes_precision, 'recall': bayes_recall, 'f1_score': bayes_f1_score}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzdsUnduXWgM"
      },
      "source": [
        "# **Comparison of the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MJ7MaFQQXsoi",
        "outputId": "b931285a-30e5-44f7-fa96-74d19429d7c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-58ae0861-5762-41a6-bd48-08ec35a05412\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.821782</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.825871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.816327</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.808081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.814815</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58ae0861-5762-41a6-bd48-08ec35a05412')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58ae0861-5762-41a6-bd48-08ec35a05412 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58ae0861-5762-41a6-bd48-08ec35a05412');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     precision  recall  f1_score\n",
              "SVM                   0.821782    0.83  0.825871\n",
              "Logistic Regression   0.816327    0.80  0.808081\n",
              "Naive Bayes           0.814815    0.88  0.846154"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame.from_dict(metric_dict, orient='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uPQ-sIghARZ"
      },
      "source": [
        "# **Pickling necessary features for later use**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llv6JqUggi2Q"
      },
      "outputs": [],
      "source": [
        "import pickle \n",
        "pickle_out = open(\"X_train.pickel\", \"wb\")\n",
        "pickle.dump(X_train, pickle_out)\n",
        "pickle_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMgiH2yaiFSk"
      },
      "outputs": [],
      "source": [
        "pickle_out = open(\"final_bayes.pickel\", \"wb\")\n",
        "pickle.dump(bayes, pickle_out)\n",
        "pickle_out.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNb2TrIB6xLvN/841MMoTwu",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
